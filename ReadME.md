<h1 align = 'center'>SOYBEAN ANALISIS WITH DEEP LEARNING TECHINCS</h1>

<strong><p align = center> GUSTAVO HENRIQUE D'ANUNCIA√á√ÉO FERREIRA</p></strong>

<h2 align = 'center'> ‚ùì Resumo </h2>

<b>Esta implementa√ß√£o consiste na an√°lise e tratamento dos dados contidos no arquivo "soybean.csv" e da cria√ß√£o de um modelo de previs√£o utilizando t√©cnicas de deep learning</b>

<h2 align = 'center'>üß©Apresenta√ß√£o da estrutura:</h2>

- As seguintes bibliotecas foram usadas durante a implementa√ß√£o:

```python
import pandas as pd
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from tensorflow.keras.utils import to_categorical
import tensorflow as tf
from keras.models import Sequential #Classificador
from keras.layers import Dense, Dropout # Neuronio
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
```

O pandas ser√° utilizado para a leitura dos dados;

O numpy ser√° usado para algumas opera√ß√µes uteis durante a an√°lise;

Scikit-Learn ser√° utilizado para codifica√ß√£o de categorias, normaliza√ß√£o de dados, divis√£o dos dados em treino e teste e para a an√°lise de metricas de erro;

O tensorflow e o Keras ser√£o utilizados para a cria√ß√£o e configura√ß√£o da rede neural artificial;

A matplotlib e o seaborn ser√£o uteis para a visualiza√ß√£o das metricas de erro e para a visualiza√ß√£o da performance do modelo;

- Leitura e tratamento inicial de dom√≠nio dos dados

```python
caminho = "./DADOS/soybean.csv"

def trantando_dominio(caminho_ds):

    ds = pd.read_csv(caminho_ds)

    for coluna in ds.columns:

        moda = ds[coluna].mode()[0]

        ds[coluna] = ds[coluna].replace('?', moda)

    return ds

soybean = trantando_dominio(caminho)

label = LabelEncoder()
classLabel = LabelEncoder()
```

Primeiro, o caminho referente √† localiza√ß√£o dos dados de entrada (soybean.csv) √© referenciado e, caso a localiza√ß√£o do arquivo seja modificada, a vari√°vel "caminho" deve ser atualizada com o endere√ßo correto.

A fun√ß√£o "tratando_dominio" recebe o caminho para o arquivo como entrada, realiza a leitura dos dados e faz o tratamento inicial dos dados inconsistentes com o dom√≠nio a cada atributo.
Esses dados fora do dom√≠nio est√£o representados como '?' dentro dos registros e, por se tratarem de variaveis categoricas, devem ser substituidos pelo valor da moda dentro do atributo em quest√£o. A fun√ß√£o passa por todos os atributos (colunas) do dataset, realiza esse tratamento dos dados e retorna o dataset j√° atualizado com os dados devidamente tratados.

Por fim, o objeto contendo o dataset √© criado, juntamente com os objetos que ser√£o usados para codifica√ß√£o dos atributos e da classe.

- Separa√ß√£o dos dados entre atributos e classe:

```python
atributos = soybean.iloc[:, 1:35].values
classe = soybean.iloc[:, 35].values
```

Como o atributo localizado originalmente na coluna 0 do dataset n√£o tem valor de peso para a classifica√ß√£o, ele √© removido durante a sele√ß√£o de atributos.

- Codifica√ß√£o de atributos e preven√ß√£o de problemas de auto-correla√ß√£o:

```python
#Label Encoding dos atributos
for i in range(34):
  atributos[:,i] = label.fit_transform(atributos[:,i])

# previnindo problema de autocorrela√ß√£o excluindo a ultima coluna

atributos = atributos[:, 0:33]

# Label Encoding da classe

classe = classLabel.fit_transform(classe)

```

Devido ao fato de todas as inst√¢ncias do dataset se tratarem de dados categ√≥ricos, √© necess√°rio a aplica√ß√£o do LabelEncoder em todas as colunas que comp√µem os atributos e tabm√©m para a classe.

O LabelEncoder ir√° associar um valor inteiro para cada registro √∫nico da coluna em quest√£o.

- Divis√£o dos dados entre treino e teste

```python
x_treino, x_teste, y_treino, y_teste = train_test_split(atributos, classe, test_size=0.3, random_state=0)
```

Nessa divis√£o, os dados de treino representam 70% dos registros e os outros 30% ficam para os dados de teste.

- Tratamento dos dados de treino e teste para inser√ß√£o correta no modelo

```python
# arrumando erro de tipo de entrada. aparentemente, o array com os dados de cada categoria deve ser convertido
# para o tipo de array desejado pela rede. um tensor_array.

x_treino = tf.convert_to_tensor(x_treino, dtype=tf.float32)
y_treino = tf.convert_to_tensor(y_treino, dtype=tf.float32)
x_teste = tf.convert_to_tensor(x_teste, dtype=tf.float32)
y_teste = tf.convert_to_tensor(y_teste, dtype=tf.float32)

# normaliza√ß√£o dos dados com z-score

normalizador = StandardScaler()

x_treino = normalizador.fit_transform(x_treino)
x_teste = normalizador.fit_transform(x_teste)

# Dummy_encoding

y_treino = to_categorical(y_treino, 19)
y_teste = to_categorical(y_teste, 19)
```

Primeiramente, os dados de treino e teste s√£o convertidos de numpy_array para tensor_array que √© um formato de array reconhecido pelo modelo de RNA. Neste processo, o tipo de dado √© convertido para float32 para que a normaliza√ß√£o seja poss√≠vel.

Com os arrays convertidos, os atributos e a classe s√£o tratados de formas diferentes:

Para os atributos, √© realizada uma normaliza√ß√£o dos dados utilizando o z-score. A normaliza√ß√£o dos dados pode contribuir para uma melhor performance do modelo.

Para a classe, √© necess√°rio que elas sejam passadas para o formato de dummy_class, que √© representada por um array contendo 0's e 1's, onde a posi√ß√£o contendo o valor 1 representa a classe dos atributos em quest√£o. Neste formato: [0., 0., 0., 1., 0., 0.,]

- Configura√ß√£o, compila√ß√£o e treinamento do modelo:

```python
#modelagem da rede -> 33 atributos de entrada, 2 camadas ocultas com 17 e 16 neuronios e 19 neuronios de saida

rede = Sequential()

rede.add(Dense(units=17, kernel_initializer= 'uniform', activation= 'relu', input_dim = 33)) # camada oculta com informa√ß√£o da entrada
rede.add(Dropout(0.2))
rede.add(Dense(units=16, kernel_initializer= 'uniform', activation= 'relu')) # camada oculta
rede.add(Dropout(0.2))

rede.add(Dense(units=19, kernel_initializer='uniform', activation='softmax')) # camada de saida

rede.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics=['accuracy'])

treinamento = rede.fit(x_treino, y_treino, epochs=500, validation_data= (x_teste, y_teste))
```

Com todo o tratamento dos dados finalizado, o modelo pode finalmente ser configurado.

O modelo utilizado nessa implementa√ß√£o foi o Sequential.
O modelo de RNA Sequential √© uma arquitetura de rede neural feedforward simples e linear que √© comumente usada em tarefas de deep learning. √â chamado de "sequencial" porque o modelo √© criado camada por camada, em sequ√™ncia.

A primeira camada oculta cont√©m 17 neur√¥nios, e tamb√©m cont√©m a informa√ß√£o dos par√¢metro de entrada.
A segunda camada oculta cont√©m 16 neur√¥nios. Ambas as camadas utilizam a fun√ß√£o de ativa√ß√£o 'relu'.
Ap√≥s cada camada oculta, foi adicionado um Dropout de 20%, que serve para previnir o "overfitting" que √© um problema de superajuste.

Para a camada de sa√≠da, 19 neuronios s√£o adicionados, representando a quantidade de classes que devem ser previstas. A camada de sa√≠da utilizada √© a "softmax" pois a resposta para a classe ser√° dada em termos de probabilidade.

Depois de criada, a rede √© compilada usando o optimizador "adam" que √© um optimizador recomendado e a fun√ß√£o de perda passada √© a "categorical_crossentropy" pois se trata de um problema de classifica√ß√£o multiclasse. Utilizamos o "accuracy" como metrica de erro.

Por fim, o modelo √© treinado atrav√©s do m√©todo .fit passando os dados de treino como os 2 primeiros hiperpar√¢metros e o n√∫mero de epochs (vezes que os dados s√£o submetidos √† RNA) pode ser alterado ajustando o hiperpar√¢metro "epochs". Como padr√£o, o n√∫mero de epochs foi definido como 500, mas o modelo pode ser treinado com qualquer n√∫mero de epochs.

N√£o √© necess√°rio criar um bloco de c√≥digo com o calculo das m√©tricas de erro, j√° que o modelo de RNA j√° faz esse calculo durante o treinamento, basta passar uma tupla contendo os dados de teste (respectivamente) para o hiperpar√¢metro "validation_data"

- Enfim, as m√©tricas de erro e a performance do modelo podem ser visualizadas

```python
#visualiza√ß√£o das metricas de erro

treinamento.history.keys()
plt.plot(treinamento.history['val_loss']) # evolu√ß√£o do erro

plt.plot(treinamento.history['val_accuracy'])

previsoes = rede.predict(x_teste)

previsoes

# matriz de confusao

y_teste_matriz = [np.argmax(t) for t in y_teste]
previsoes_matriz = [np.argmax(t) for t in previsoes]

confusao = confusion_matrix(y_teste_matriz, previsoes_matriz)

plt.figure(figsize=(8, 6))
sns.set(font_scale=1.2)
sns.heatmap(confusao, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Classe Predita')
plt.ylabel('Classe Real')
plt.title('Matriz de Confus√£o')
plt.show()
```

Para a visualiza√ß√£o das m√©tricas de erro, um gr√°fico √© gerado:

<div align = center> <img align src = /img/erro.jpg> </div>

Em azul temos a "evolu√ß√£o" do erro e em laranja a evolu√ß√£o da performance do modelo. Pode-se notar que, como √© o esperado, enquanto o valor do erro cai a cada epoch, a performance aumenta.

Para a visualiza√ß√£o da performance do modelo, uma matriz de confus√£o √© gerada:

<div align = center> <img align src = /img/confusao.jpg> </div>

Na diagonal principal, est√£o os dados classificados corretamente pelo modelo, e nas posi√ß√µes adjacentes da matriz os erros.

<h2 align = center>üîß Compila√ß√£o e execu√ß√£o </h2>

Para compila√ß√£o e execu√ß√£o correta do c√≥digo, a vers√£o recomendada do Python √© a 3.8.x ou superiores.

Tamb√©m √© importante ressaltar que as bibliotecas devem estar instaladas corretamente no ambiente de execu√ß√£o, caso contr√°rio, erros v√£o ocorrer.